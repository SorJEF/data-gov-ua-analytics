input {
  file {
    path => "/crawler/data/metadata*.json"
    type => "metadata"  # a type to identify those logs (will need this later)
    start_position => "beginning"
    codec => json{ }
  }
}
filter {
  date {
    match => [ "created", "dd.MM.YYYY HH:mm" ]
    target => "created"
  }
  date {
    match => [ "changed", "dd.MM.YYYY HH:mm" ]
    target => "changed"
  }
  mutate {
    convert => { "revision_id" => "integer" }
    convert => { "last_revision_id" => "integer" }
    convert => { "files.filesize" => "integer" }
  }
  ruby {
    code => '
      require "geocoder";
      Geocoder.configure(
        :lookup => :yandex,
        :timeout => 30,
        :http_proxy => "proxy:8118",
        :https_proxy => "proxy:8118"
      );
      result = Geocoder.search(event.get("[author][address]")).select { |item| item.country == "Ukraine" };
      if result.any?
        first = result[0];
        event.set("[author][location]", first.coordinates.join(","));
        event.set("[author][city]", first.city);
        event.set("[author][state]", first.state);
        event.set("[author][postal_code]", first.postal_code);
      end
    '
  }
}
output {
  elasticsearch {
    hosts => "elasticsearch:9200"
    index => "data.gov.ua-%{+YYYY.MM.dd}"
    document_id => "%{dataset_id}"
    template_name => "data.gov.ua"
    template => "/crawler/logstash/data.gov.ua-template.json"
    template_overwrite => true
  }
}
